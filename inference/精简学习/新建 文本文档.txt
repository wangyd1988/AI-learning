DeepSeek 在 Hopper GPU(例如H800)的 推理阶段的Decoder注意力(即“多头注意力解码”)部分做深度优化。FlashAttention 已经够快了，但还是有一定的通用性牺牲了“硬件特定优化”的空间

一方面充分利用 Hopper 的特性（例如新的 Tensor Core、BF16 性能、带宽分配等），另一方面针对可变序列长度、分页 KV 缓存做专门的内核代码，以达到更高的带宽利用率和算力效率。


"硬件+算子双重定制”方案，通过继承 FlashAttention（减少内存冗余）的思路，和结合 Hopper GPU 的硬件细节进行极限级别的性能调教。结果就是带宽能到 3000 GB/s，算力打到 580 TFLOPS，



在专家并行（EP）中，当专家被分配到不同 GPU 上，会导致工作负载不平衡。DeepSeek-V3 通过“冗余专家”策略解决了这一问题，复制高负载专家并以启发式方法分配以达到平衡。组限制专家路由（Group-Limited Expert Routing）通过将同组专家尽可能放置在同一节点上，进一步减少跨节点数据流量。开源的 eplb.py 算法计算了平衡的专家复制与分配。他们还引入了 DualPipe，这是一种双向流水线并行算法，能够并行实现正向与反向计算-通信阶段，同时减少流水线气泡(空闲时间)。 


DeepSeek利用（专家并行负载均衡器）
EPLB，即专家并行负载均衡器。使用专家并行（EP）时，会将不同的专家分配到不同的GPU
EPLB(专家并行负载均衡器)通过复制高负载专家到GPU，解决专家并行中工作负载不平衡的问题。


EPLB(专家并行负载均衡器) 采用了冗余专家策略和分层/全局负载均衡策略，对高负载专家进行复制和组限制路由，来分散计算压力和分层负载均衡策略,确保每个 GPU 的负载尽可能均衡，同时显著提升模型推理效率。